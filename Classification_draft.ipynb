{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "from os import path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/data/neoclassicism-neoexpressionism-100\"\n",
    "\n",
    "data_cat = ('train-before', 'train-after', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = 32\n",
    "batch_size = 64\n",
    "scale = 360\n",
    "use_parallel = True\n",
    "use_gpu = True\n",
    "epochs = 100\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize(scale),\n",
    "        transforms.RandomResizedCrop(input_shape),\n",
    "        transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {x: datasets.ImageFolder(path.join(data_dir, x), data_transforms) for x in data_cat}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=4) for x in data_cat}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in data_cat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader = dataloaders['train-after'], dataloaders['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 20\n",
      "    Root Location: /data/neoclassicism-neoexpressionism-100/train-before\n",
      "    Transforms (if any): Compose(\n",
      "                             Resize(size=32, interpolation=PIL.Image.BILINEAR)\n",
      "                             ToTensor()\n",
      "                         )\n",
      "    Target Transforms (if any): None\n",
      "['c', 'e']\n"
     ]
    }
   ],
   "source": [
    "print(image_datasets['train-before'])\n",
    "classes = image_datasets['train-before'].classes\n",
    "print(classes)\n",
    "\n",
    "# print(image_datasets['train-before'].__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Traceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 187, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 187, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 164, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 32 and 42 in dimension 2 at /opt/conda/conda-bld/pytorch_1532582123400/work/aten/src/TH/generic/THTensorMath.cpp:3616\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a759e3053fce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# get some random training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# show images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Traceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 187, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 187, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 164, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 32 and 42 in dimension 2 at /opt/conda/conda-bld/pytorch_1532582123400/work/aten/src/TH/generic/THTensorMath.cpp:3616\n"
     ]
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(images.shape)\n",
    "# print labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "Copy the neural network from the Neural Networks section before and modify it to\n",
    "take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, epoch, criterion, optimizer, log_step, device = \"cuda\"):\n",
    "    \n",
    "    model.to(device)\n",
    "        \n",
    "    for epoch in range(epoch):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % log_step == log_step-1:    \n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / log_step))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.690\n",
      "[1,    20] loss: 0.693\n",
      "[1,    30] loss: 0.684\n",
      "[1,    40] loss: 0.668\n",
      "[1,    50] loss: 0.654\n",
      "[1,    60] loss: 0.639\n",
      "[2,    10] loss: 0.635\n",
      "[2,    20] loss: 0.590\n",
      "[2,    30] loss: 0.610\n",
      "[2,    40] loss: 0.568\n",
      "[2,    50] loss: 0.580\n",
      "[2,    60] loss: 0.566\n",
      "[3,    10] loss: 0.459\n",
      "[3,    20] loss: 0.441\n",
      "[3,    30] loss: 0.406\n",
      "[3,    40] loss: 0.420\n",
      "[3,    50] loss: 0.427\n",
      "[3,    60] loss: 0.349\n",
      "[4,    10] loss: 0.369\n",
      "[4,    20] loss: 0.341\n",
      "[4,    30] loss: 0.317\n",
      "[4,    40] loss: 0.337\n",
      "[4,    50] loss: 0.325\n",
      "[4,    60] loss: 0.325\n",
      "[5,    10] loss: 0.365\n",
      "[5,    20] loss: 0.319\n",
      "[5,    30] loss: 0.294\n",
      "[5,    40] loss: 0.305\n",
      "[5,    50] loss: 0.291\n",
      "[5,    60] loss: 0.315\n",
      "[6,    10] loss: 0.280\n",
      "[6,    20] loss: 0.261\n",
      "[6,    30] loss: 0.292\n",
      "[6,    40] loss: 0.301\n",
      "[6,    50] loss: 0.283\n",
      "[6,    60] loss: 0.276\n",
      "[7,    10] loss: 0.261\n",
      "[7,    20] loss: 0.303\n",
      "[7,    30] loss: 0.301\n",
      "[7,    40] loss: 0.259\n",
      "[7,    50] loss: 0.306\n",
      "[7,    60] loss: 0.251\n",
      "[8,    10] loss: 0.281\n",
      "[8,    20] loss: 0.231\n",
      "[8,    30] loss: 0.265\n",
      "[8,    40] loss: 0.280\n",
      "[8,    50] loss: 0.239\n",
      "[8,    60] loss: 0.243\n",
      "[9,    10] loss: 0.254\n",
      "[9,    20] loss: 0.224\n",
      "[9,    30] loss: 0.231\n",
      "[9,    40] loss: 0.257\n",
      "[9,    50] loss: 0.242\n",
      "[9,    60] loss: 0.243\n",
      "[10,    10] loss: 0.262\n",
      "[10,    20] loss: 0.292\n",
      "[10,    30] loss: 0.243\n",
      "[10,    40] loss: 0.217\n",
      "[10,    50] loss: 0.249\n",
      "[10,    60] loss: 0.238\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, trainloader, epoch, criterion, optimizer, log_step = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, num_classes, batch, device = \"cuda\"):\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    class_correct = list(0. for i in range(num_classes))\n",
    "    class_total = list(0. for i in range(num_classes))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            c = (predicted == labels).squeeze()\n",
    "            \n",
    "            for i in range(batch):           \n",
    "                if i >= len(labels):\n",
    "                    break\n",
    "                \n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "    \n",
    "    print(correct, total)\n",
    "    print('Accuracy of the network on the test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 180\n",
      "Accuracy of the network on the test images: 58 %\n",
      "Accuracy of     c : 55 %\n",
      "Accuracy of     e : 62 %\n"
     ]
    }
   ],
   "source": [
    "# print(len(testloader.data))\n",
    "# print(testloader)\n",
    "test(net, testloader, len(classes), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
